{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "WdIAHH3y1MGL",
        "Px6y2YSkQb_C",
        "P2ULXjC2r2G1",
        "pua8lra2sVWf",
        "Ub3zPKGT1fiy",
        "KI7xuMEbZFPD",
        "vYvf9mwNNnmf"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6946523,
          "sourceType": "datasetVersion",
          "datasetId": 3989497
        },
        {
          "sourceId": 6997104,
          "sourceType": "datasetVersion",
          "datasetId": 4022200
        }
      ],
      "dockerImageVersionId": 30588,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1-Import Libraries"
      ],
      "metadata": {
        "id": "WdIAHH3y1MGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, datetime, warnings, logging, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras,cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from tqdm.notebook import tqdm\n",
        "import glob, random, time, shutil\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D, BatchNormalization, Activation, Input, Add, Dense, ZeroPadding2D,Flatten, AveragePooling2D, Rescaling, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import metrics\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, Callback,ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "qH4lmQYsrspb",
        "execution": {
          "iopub.status.busy": "2023-11-18T16:25:22.856025Z",
          "iopub.execute_input": "2023-11-18T16:25:22.856749Z",
          "iopub.status.idle": "2023-11-18T16:25:22.865935Z",
          "shell.execute_reply.started": "2023-11-18T16:25:22.856714Z",
          "shell.execute_reply": "2023-11-18T16:25:22.864879Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenetV2_preprocessing\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as InceptionV3_preprocessing"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-18T16:25:22.868255Z",
          "iopub.execute_input": "2023-11-18T16:25:22.868619Z",
          "iopub.status.idle": "2023-11-18T16:25:22.883089Z",
          "shell.execute_reply.started": "2023-11-18T16:25:22.868589Z",
          "shell.execute_reply": "2023-11-18T16:25:22.882301Z"
        },
        "trusted": true,
        "id": "e02XeAl1_2f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-Fix randomness and hide warnings"
      ],
      "metadata": {
        "id": "P2ULXjC2r2G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix randomness and hide warnings\n",
        "SEED = 42\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "np.random.seed(SEED)\n",
        "\n",
        "import logging\n",
        "\n",
        "random.seed(SEED)"
      ],
      "metadata": {
        "id": "oEYVRRdgMuWt",
        "execution": {
          "iopub.status.busy": "2023-11-18T16:25:22.884159Z",
          "iopub.execute_input": "2023-11-18T16:25:22.884430Z",
          "iopub.status.idle": "2023-11-18T16:25:22.896274Z",
          "shell.execute_reply.started": "2023-11-18T16:25:22.884399Z",
          "shell.execute_reply": "2023-11-18T16:25:22.895466Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-Set first parameters of tensorflow"
      ],
      "metadata": {
        "id": "pua8lra2sVWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tensorflow\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.random.set_seed(SEED)\n",
        "tf.compat.v1.set_random_seed(SEED)\n",
        "print(\"tensorflow_version\",tf.__version__)"
      ],
      "metadata": {
        "id": "WC9nG5HlMvHd",
        "execution": {
          "iopub.status.busy": "2023-11-18T16:25:22.897275Z",
          "iopub.execute_input": "2023-11-18T16:25:22.897521Z",
          "iopub.status.idle": "2023-11-18T16:25:22.910900Z",
          "shell.execute_reply.started": "2023-11-18T16:25:22.897500Z",
          "shell.execute_reply": "2023-11-18T16:25:22.909919Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-Read DATA"
      ],
      "metadata": {
        "id": "vfqGa0UD_2f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = np.load(\"/kaggle/input/a2ndl-farm/public_data.npz\", allow_pickle=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-18T16:25:26.123685Z",
          "iopub.execute_input": "2023-11-18T16:25:26.124041Z",
          "iopub.status.idle": "2023-11-18T16:25:26.179892Z",
          "shell.execute_reply.started": "2023-11-18T16:25:26.124009Z",
          "shell.execute_reply": "2023-11-18T16:25:26.178804Z"
        },
        "trusted": true,
        "id": "IaFVibhR_2f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-Data Inspection"
      ],
      "metadata": {
        "id": "Ub3zPKGT1fiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = list(dataset.keys())\n",
        "print('keys in our dataset are: ', keys)\n",
        "\n",
        "#data shape\n",
        "images = dataset[\"data\"]\n",
        "no_images = images.shape[0]\n",
        "size_images = images.shape[1:3]\n",
        "print('Data shape: ',images.shape)\n",
        "\n",
        "#labels\n",
        "labels = dataset[\"labels\"]\n",
        "no_labels = labels.shape[0]\n",
        "\n",
        "#check balanced or imbalanced of DATA\n",
        "unique_classes, counts = np.unique(labels,return_counts=True)\n",
        "for cls, count in zip(unique_classes, counts):\n",
        "    print(f\"Class {cls}: {count} data points\")"
      ],
      "metadata": {
        "id": "Ay-MIDxM1dvU",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:07.454844Z",
          "iopub.execute_input": "2023-11-17T00:09:07.455173Z",
          "iopub.status.idle": "2023-11-17T00:09:12.996408Z",
          "shell.execute_reply.started": "2023-11-17T00:09:07.455150Z",
          "shell.execute_reply": "2023-11-17T00:09:12.995314Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6_Show images"
      ],
      "metadata": {
        "id": "KI7xuMEbZFPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the string labels to integer labels\n",
        "integer_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Convert integers to binary labels (0 or 1)\n",
        "binary_labels = np.where(integer_labels == 1, 1, 0)"
      ],
      "metadata": {
        "id": "eu4sX-LHAJji",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:12.997669Z",
          "iopub.execute_input": "2023-11-17T00:09:12.997974Z",
          "iopub.status.idle": "2023-11-17T00:09:13.005019Z",
          "shell.execute_reply.started": "2023-11-17T00:09:12.997949Z",
          "shell.execute_reply": "2023-11-17T00:09:13.003946Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(dataset, labels, batch_no, no_images_per_batch, num_cols=10):\n",
        "\n",
        "    start_index = batch_no * no_images_per_batch\n",
        "    end_index = min((batch_no + 1) * no_images_per_batch, len(dataset))\n",
        "    num_rows = (end_index - start_index + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
        "\n",
        "    for i, ax in enumerate(axes.ravel()):\n",
        "        if start_index + i < end_index:\n",
        "            image = dataset[start_index + i]\n",
        "            image = image / 255.0  # Normalize pixel values to [0, 1]\n",
        "            ax.imshow(image)\n",
        "            ax.set_title(f\"{labels[start_index + i]}\",fontsize=10, y=-0.5)\n",
        "            ax.axis('off')\n",
        "\n",
        "    for i in range(end_index - start_index, num_rows * num_cols):\n",
        "        fig.delaxes(axes.flatten()[i])\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bf1SDKlIZbCg",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:13.006453Z",
          "iopub.execute_input": "2023-11-17T00:09:13.006785Z",
          "iopub.status.idle": "2023-11-17T00:09:13.017732Z",
          "shell.execute_reply.started": "2023-11-17T00:09:13.006757Z",
          "shell.execute_reply": "2023-11-17T00:09:13.017000Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(dataset=images,labels =binary_labels, batch_no=0,no_images_per_batch=60)"
      ],
      "metadata": {
        "id": "jWSVSRfKZdOl",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:13.018740Z",
          "iopub.execute_input": "2023-11-17T00:09:13.019007Z",
          "iopub.status.idle": "2023-11-17T00:09:15.172618Z",
          "shell.execute_reply.started": "2023-11-17T00:09:13.018984Z",
          "shell.execute_reply": "2023-11-17T00:09:15.170037Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7-Remove Outliers"
      ],
      "metadata": {
        "id": "vYvf9mwNNnmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# there are some uselees images in dataset which must be first recognized and then remoeved.\n",
        "\n",
        "def histogram_similarity(image, reference_histogram, threshold=0.8):\n",
        "\n",
        "    # Calculate the color histogram of the image\n",
        "    image_histogram = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "    cv2.normalize(image_histogram, image_histogram)\n",
        "    intersection = cv2.compareHist(reference_histogram, image_histogram, cv2.HISTCMP_INTERSECT)\n",
        "\n",
        "    return intersection < threshold\n",
        "\n",
        "\n",
        "# Load a reference histogram from a non-Shrek-Singer image\n",
        "reference_image = images[0]  # Use the first image as a reference which it's a leaf image\n",
        "reference_histogram = cv2.calcHist([reference_image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "cv2.normalize(reference_histogram, reference_histogram)\n",
        "\n",
        "similarity_threshold = 0.62\n",
        "odd_images = []\n",
        "\n",
        "# Iterate through the images in data_array\n",
        "for image in images:\n",
        "    if histogram_similarity(image, reference_histogram, similarity_threshold):\n",
        "        odd_images.append(image)"
      ],
      "metadata": {
        "id": "0EMa6m_1Nb9u",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:15.177729Z",
          "iopub.execute_input": "2023-11-17T00:09:15.178411Z",
          "iopub.status.idle": "2023-11-17T00:09:16.602739Z",
          "shell.execute_reply.started": "2023-11-17T00:09:15.178376Z",
          "shell.execute_reply": "2023-11-17T00:09:16.601858Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating reference images\n",
        "reference_unwanted_images = []\n",
        "\n",
        "# Define the index of the image we want to plot and save as a reference\n",
        "image_index_trololo = 10  # Replace with the index of the reference image\n",
        "image_index_shrek = 33\n",
        "\n",
        "if 0 <= image_index_trololo  and image_index_shrek< len(odd_images):\n",
        "    # Get the image based on the index\n",
        "    trololo_reference_image = odd_images[image_index_trololo]\n",
        "    shrek_reference_image = odd_images[image_index_shrek]\n",
        "\n",
        "    reference_unwanted_images.append(trololo_reference_image)\n",
        "    reference_unwanted_images.append(shrek_reference_image)\n",
        "\n",
        "else:\n",
        "    print(\"Invalid image index.\")"
      ],
      "metadata": {
        "id": "flWTO2StPpOn",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:16.603894Z",
          "iopub.execute_input": "2023-11-17T00:09:16.604220Z",
          "iopub.status.idle": "2023-11-17T00:09:16.610699Z",
          "shell.execute_reply.started": "2023-11-17T00:09:16.604194Z",
          "shell.execute_reply": "2023-11-17T00:09:16.609718Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import rgb2lab, deltaE_cie76\n",
        "\n",
        "#Calculate the color distance between two images using the CIE76 metric.\n",
        "def calculate_color_distance(image1, image2):\n",
        "\n",
        "    lab_image1 = rgb2lab(image1)\n",
        "    lab_image2 = rgb2lab(image2)\n",
        "\n",
        "    return deltaE_cie76(lab_image1, lab_image2)\n",
        "\n",
        "def find_unwanted_images_by_color_distance(data_array, reference_unwanted_images, color_distance_threshold):\n",
        "\n",
        "    cleaned_data = []\n",
        "    unwanted_images = []\n",
        "    labels_index =[]\n",
        "    outlier_labels_index=[]\n",
        "    index =0\n",
        "    for image in data_array:\n",
        "        similar = False\n",
        "        for reference_image in reference_unwanted_images:\n",
        "            color_distance = calculate_color_distance(image, reference_image)\n",
        "            if (color_distance < color_distance_threshold).all():\n",
        "                similar = True\n",
        "                break  # No need to check further if a match is found\n",
        "        if (similar == True):\n",
        "            unwanted_images.append(image)\n",
        "            labels_index.append(index)\n",
        "        else:\n",
        "            cleaned_data.append(image)\n",
        "            outlier_labels_index.append(index)\n",
        "\n",
        "        index+=1\n",
        "\n",
        "    return cleaned_data,unwanted_images, labels_index\n",
        "\n",
        "color_distance_threshold = 1"
      ],
      "metadata": {
        "id": "_phUYj8UP6tP",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:16.611998Z",
          "iopub.execute_input": "2023-11-17T00:09:16.612330Z",
          "iopub.status.idle": "2023-11-17T00:09:16.680128Z",
          "shell.execute_reply.started": "2023-11-17T00:09:16.612299Z",
          "shell.execute_reply": "2023-11-17T00:09:16.679219Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_images,unwanted_images, labels_index = find_unwanted_images_by_color_distance(images, reference_unwanted_images, color_distance_threshold)"
      ],
      "metadata": {
        "id": "YMTgF4kZQEAG",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:16.681212Z",
          "iopub.execute_input": "2023-11-17T00:09:16.681529Z",
          "iopub.status.idle": "2023-11-17T00:09:33.761014Z",
          "shell.execute_reply.started": "2023-11-17T00:09:16.681502Z",
          "shell.execute_reply": "2023-11-17T00:09:33.759927Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unwanted_images = np.stack(unwanted_images, axis=0) # Define new shape for unwanted_images\n",
        "unwanted_images.shape"
      ],
      "metadata": {
        "id": "GbJgZNUuQQfW",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:33.762449Z",
          "iopub.execute_input": "2023-11-17T00:09:33.762776Z",
          "iopub.status.idle": "2023-11-17T00:09:33.778313Z",
          "shell.execute_reply.started": "2023-11-17T00:09:33.762748Z",
          "shell.execute_reply": "2023-11-17T00:09:33.777290Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_images = np.stack(cleaned_images, axis=0)\n",
        "cleaned_images.shape"
      ],
      "metadata": {
        "id": "DT_A9Ie3RbjP",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:33.779677Z",
          "iopub.execute_input": "2023-11-17T00:09:33.780118Z",
          "iopub.status.idle": "2023-11-17T00:09:33.966180Z",
          "shell.execute_reply.started": "2023-11-17T00:09:33.780069Z",
          "shell.execute_reply": "2023-11-17T00:09:33.965195Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a boolean mask for the values to keep\n",
        "mask = np.ones(binary_labels.shape[0], dtype=bool)\n",
        "mask[labels_index] = False\n",
        "\n",
        "cleaned_labels = binary_labels[mask]\n",
        "outlier_labels=binary_labels[labels_index]"
      ],
      "metadata": {
        "id": "C1gJ81UdRjc4",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:33.967533Z",
          "iopub.execute_input": "2023-11-17T00:09:33.967952Z",
          "iopub.status.idle": "2023-11-17T00:09:33.973110Z",
          "shell.execute_reply.started": "2023-11-17T00:09:33.967922Z",
          "shell.execute_reply": "2023-11-17T00:09:33.972185Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" \"*25,end=\" \")\n",
        "print(\"Unwanted Images \",end=' '*25)\n",
        "show_images(dataset=unwanted_images,labels=outlier_labels, batch_no=0,no_images_per_batch=10)"
      ],
      "metadata": {
        "id": "fLjmSabQ3-79",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:33.974198Z",
          "iopub.execute_input": "2023-11-17T00:09:33.974603Z",
          "iopub.status.idle": "2023-11-17T00:09:34.341566Z",
          "shell.execute_reply.started": "2023-11-17T00:09:33.974570Z",
          "shell.execute_reply": "2023-11-17T00:09:34.340026Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" \"*25,end=\" \")\n",
        "print(\"Cleaned Images \",end=' '*25)\n",
        "show_images(dataset=cleaned_images,labels =cleaned_labels, batch_no=0,no_images_per_batch=10)"
      ],
      "metadata": {
        "id": "qWPSJzZV4vxw",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:34.344125Z",
          "iopub.execute_input": "2023-11-17T00:09:34.345099Z",
          "iopub.status.idle": "2023-11-17T00:09:34.751404Z",
          "shell.execute_reply.started": "2023-11-17T00:09:34.345050Z",
          "shell.execute_reply": "2023-11-17T00:09:34.749778Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_images = cleaned_images.shape[0]\n",
        "no_labels = cleaned_labels.shape[0]\n",
        "_, counts = np.unique(cleaned_labels,return_counts=True) # count occurrence of each item\n",
        "no_healthy_images = counts[0]\n",
        "no_unhealthy_images = counts[1]\n",
        "\n",
        "# pass variables to a dictionary to be used as dataframe for a better show\n",
        "info_table_dict = {\"no. images\":no_images, \"image width\": size_images[0],\"image length\": size_images[1], \"no. labels\":no_labels,\n",
        "                   \"no. healthy_images\":no_healthy_images,\"percentage%\":no_healthy_images*100/no_labels,\n",
        "                   \"no. unhealthy_images\":no_unhealthy_images,\"percentage %\":no_unhealthy_images*100/no_labels }\n",
        "print(\" \"*42,end=\" \")\n",
        "print(\"Table after Removing Outliers \",end=' '*42)\n",
        "info_table = pd.DataFrame(info_table_dict, index =['value'])\n",
        "info_table"
      ],
      "metadata": {
        "id": "OJM58pT52Fd1",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:34.753844Z",
          "iopub.execute_input": "2023-11-17T00:09:34.754353Z",
          "iopub.status.idle": "2023-11-17T00:09:34.794130Z",
          "shell.execute_reply.started": "2023-11-17T00:09:34.754307Z",
          "shell.execute_reply": "2023-11-17T00:09:34.793129Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8-Class Weight"
      ],
      "metadata": {
        "id": "ufWagxZ-_2f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate class frequencies\n",
        "class_frequencies = np.sum(np.array(category_labels), axis=0)\n",
        "\n",
        "# Calculate class weights inversely proportional to class frequencies\n",
        "total_samples = np.sum(class_frequencies)\n",
        "class_weights = {i: total_samples / (len(class_frequencies) * freq) for i, freq in enumerate(class_frequencies)}"
      ],
      "metadata": {
        "id": "lKibOr-n_2f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9-Splitting data And Augmentation"
      ],
      "metadata": {
        "id": "PrB7sWt7urCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "category_labels = to_categorical(cleaned_labels, num_classes=2)"
      ],
      "metadata": {
        "id": "aHR9CiUCy5qz",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:34.795333Z",
          "iopub.execute_input": "2023-11-17T00:09:34.795592Z",
          "iopub.status.idle": "2023-11-17T00:09:34.800619Z",
          "shell.execute_reply.started": "2023-11-17T00:09:34.795569Z",
          "shell.execute_reply": "2023-11-17T00:09:34.799657Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constructor for training data generator with augmentation\n",
        "data_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "#     height_shift_range=0.2,\n",
        "#     width_shift_range=0.2,\n",
        "    zoom_range=[0.7 , 1.3],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='reflect',\n",
        "    rescale=1./255,\n",
        "    # change this based on the network you want use!!!\n",
        "    # default : CNN e.g. 'resnet_preprocess'\n",
        "    validation_split=0.1,\n",
        "    preprocessing_function=None\n",
        ")\n",
        "\n",
        "# # Constructor for validation data generator without augmentation comment for TTA\n",
        "# data_datagen_val = ImageDataGenerator(\n",
        "#     rescale=1./255,\n",
        "#     validation_split=0.1,  # Use the same validation split\n",
        "#     preprocessing_function=None\n",
        "# )\n",
        "\n",
        "# Generator for training set\n",
        "aug_train_set = data_datagen.flow(\n",
        "    cleaned_images,\n",
        "    category_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "# Generator for validation set (with augmentation)\n",
        "validation_set = data_datagen.flow(\n",
        "    cleaned_images,\n",
        "    category_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        "    subset=\"validation\"\n",
        ")"
      ],
      "metadata": {
        "id": "RXEsdB1H7brg",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:34.802369Z",
          "iopub.execute_input": "2023-11-17T00:09:34.803329Z",
          "iopub.status.idle": "2023-11-17T00:09:34.815786Z",
          "shell.execute_reply.started": "2023-11-17T00:09:34.803301Z",
          "shell.execute_reply": "2023-11-17T00:09:34.815031Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10-Define Models"
      ],
      "metadata": {
        "id": "YGXwMsMqV5ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN**"
      ],
      "metadata": {
        "id": "w9xRWKk6_2gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_model(hp):\n",
        "    model = tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Conv2D(filters=hp.Int('conv1_filters', min_value=32, max_value=128, step=16),\n",
        "                                 kernel_size=hp.Choice('conv1_kernel', values=[3, 5]), activation='elu', input_shape=(96, 96, 3)),\n",
        "          tf.keras.layers.BatchNormalization(renorm=True),\n",
        "          tf.keras.layers.MaxPooling2D(2,2),\n",
        "          tf.keras.layers.Conv2D(filters=hp.Int('conv2_filters', min_value=64, max_value=128, step=32),\n",
        "                                 kernel_size=hp.Choice('conv2_kernel', values=[3, 5]), activation='elu'),\n",
        "          tf.keras.layers.Conv2D(filters=hp.Int('conv3_filters', min_value=64, max_value=256, step=32),\n",
        "                                 kernel_size=hp.Choice('conv3_kernel', values=[3, 5]), activation='elu'),\n",
        "          tf.keras.layers.BatchNormalization(renorm=True),\n",
        "          tf.keras.layers.MaxPooling2D(2,2),\n",
        "          tf.keras.layers.Conv2D(filters=hp.Int('conv4_filters', min_value=64, max_value=512, step=32),\n",
        "                                 kernel_size=hp.Choice('conv4_kernel', values=[3, 5]), activation='elu'),\n",
        "          tf.keras.layers.Conv2D(filters=hp.Int('conv5_filters', min_value=128, max_value=1024, step=64),\n",
        "                                 kernel_size=hp.Choice('conv5_kernel', values=[3, 5]), activation='elu'),\n",
        "          tf.keras.layers.BatchNormalization(renorm=True),\n",
        "          tf.keras.layers.Conv2D(filters=hp.Int('conv6_filters', min_value=64, max_value=512, step=64),\n",
        "                                 kernel_size=hp.Choice('conv6_kernel', values=[3, 5]), activation='elu'),\n",
        "          tf.keras.layers.Conv2D(filters=hp.Int('conv7_filters', min_value=32, max_value=256, step=16),\n",
        "                                 kernel_size=hp.Choice('conv7_kernel', values=[3, 5]), activation='elu'),\n",
        "          tf.keras.layers.GlobalMaxPooling2D(),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dropout(rate=hp.Float('dropout1_rate', min_value=0.05, max_value=0.2, step=0.05),seed=SEED),\n",
        "          tf.keras.layers.Dense(units=hp.Int('dense1_units', min_value=64, max_value=512, step=32),activation= None),\n",
        "          tf.keras.layers.Dropout(rate=hp.Float('dropout2_rate', min_value=0.4, max_value=0.6, step=0.1),seed=SEED),\n",
        "          tf.keras.layers.Dense(units=hp.Int('dense2_units', min_value=32, max_value=256, step=16),activation= None),\n",
        "          tf.keras.layers.Dense(units=hp.Int('dense3_units', min_value=32, max_value=128, step=8),\n",
        "                                activation=keras.layers.LeakyReLU(alpha=hp.Float('leaky_relu_alpha', min_value=0.01, max_value=0.3, step=0.01))),\n",
        "          tf.keras.layers.Dense(2, activation='softmax')\n",
        "          ])\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 5e-4, 1e-4]))\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "R9osAfoqiPHr",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:34.817112Z",
          "iopub.execute_input": "2023-11-17T00:09:34.817732Z",
          "iopub.status.idle": "2023-11-17T00:09:34.836796Z",
          "shell.execute_reply.started": "2023-11-17T00:09:34.817695Z",
          "shell.execute_reply": "2023-11-17T00:09:34.836057Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function for callbacks for training\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 5 , verbose=1,factor=0.3, min_lr=0.000001)\n",
        "# Model checkpoint\n",
        "mcp_save_CNN = ModelCheckpoint('model_CNN.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "metadata": {
        "id": "d3cfbcef",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:34.857258Z",
          "iopub.execute_input": "2023-11-17T00:09:34.857611Z",
          "iopub.status.idle": "2023-11-17T00:09:34.867521Z",
          "shell.execute_reply.started": "2023-11-17T00:09:34.857569Z",
          "shell.execute_reply": "2023-11-17T00:09:34.866753Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history_CNN_simple = model_CNN.fit(aug_train_set,\n",
        "#     epochs=50,\n",
        "#     verbose=1,\n",
        "#     callbacks=[learning_rate_reduction, mcp_save_CNN],\n",
        "#     validation_data= validation_set\n",
        "# )"
      ],
      "metadata": {
        "id": "cxswhQJAiq7U",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:34.868668Z",
          "iopub.execute_input": "2023-11-17T00:09:34.868981Z",
          "iopub.status.idle": "2023-11-17T00:09:34.879008Z",
          "shell.execute_reply.started": "2023-11-17T00:09:34.868957Z",
          "shell.execute_reply": "2023-11-17T00:09:34.878190Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history_CNN_deleteoutliers = model_CNN.fit(aug_train_set,\n",
        "#     epochs=50,\n",
        "#     verbose=1,\n",
        "#     callbacks=[learning_rate_reduction, mcp_save_CNN],\n",
        "#     validation_data= validation_set\n",
        "# )"
      ],
      "metadata": {
        "id": "-QyZtfSQzR6e",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:34.879896Z",
          "iopub.execute_input": "2023-11-17T00:09:34.880155Z",
          "iopub.status.idle": "2023-11-17T00:09:34.890702Z",
          "shell.execute_reply.started": "2023-11-17T00:09:34.880124Z",
          "shell.execute_reply": "2023-11-17T00:09:34.889766Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history_CNN_Aug = loaded_model.fit(aug_train_set,\n",
        "#     epochs=50,\n",
        "#     verbose=1,\n",
        "#     callbacks=[learning_rate_reduction, mcp_save_CNN],\n",
        "#     validation_data= validation_set\n",
        "# )"
      ],
      "metadata": {
        "id": "aQgwOfRw3DPt",
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:34.891969Z",
          "iopub.execute_input": "2023-11-17T00:09:34.892846Z",
          "iopub.status.idle": "2023-11-17T00:09:34.904452Z",
          "shell.execute_reply.started": "2023-11-17T00:09:34.892816Z",
          "shell.execute_reply": "2023-11-17T00:09:34.903605Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    CNN_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,  # تعداد تلاش‌ها برای جستجو\n",
        "    directory='/kaggle/working',  # مسیر ذخیره سازی نتایج\n",
        "    project_name='cnn_tuning'  # نام پروژه\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:34.909732Z",
          "iopub.execute_input": "2023-11-17T00:09:34.910051Z",
          "iopub.status.idle": "2023-11-17T00:09:40.704245Z",
          "shell.execute_reply.started": "2023-11-17T00:09:34.910020Z",
          "shell.execute_reply": "2023-11-17T00:09:40.703195Z"
        },
        "trusted": true,
        "id": "SpyIU2Sz_2gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(aug_train_set,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    callbacks=[learning_rate_reduction, mcp_save_CNN],\n",
        "    validation_data= validation_set,\n",
        "    class_weight=class_weights\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-17T00:09:40.714510Z",
          "iopub.execute_input": "2023-11-17T00:09:40.714879Z"
        },
        "trusted": true,
        "id": "ms8a-vG1_2gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "WKuLUbWD_2gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save('/kaggle/working/SubmissionModel')\n",
        "\n",
        "from shutil import make_archive\n",
        "make_archive('/kaggle/working/SubmissionModel_CNN', 'zip', '/kaggle/working/SubmissionModel')"
      ],
      "metadata": {
        "id": "rH-MD9FQIDE8",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(BASE_DIR+'history_CNN_Aug.pkl', 'wb') as file:\n",
        "#     pickle.dump(history_CNN_Aug.history, file)\n",
        "# with open(BASE_DIR+'history_CNN_simple.pkl', 'rb') as file:\n",
        "#     history_CNN_simple = pickle.load(file)\n",
        "# with open(BASE_DIR+'history_CNN_deleteoutliers.pkl', 'rb') as file:\n",
        "#     history_CNN_deleteoutliers = pickle.load(file)\n",
        "# with open(BASE_DIR+'history_CNN_Aug.pkl', 'rb') as file:\n",
        "#     history_CNN_Aug = pickle.load(file)"
      ],
      "metadata": {
        "id": "966KY-A-6U3h",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #plotting the validation and train loss\n",
        "# plt.plot(history_CNN_simple['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
        "# plt.plot(history_CNN_simple['val_loss'], label='CNN', alpha=.8, color='#ff7f0e')\n",
        "# plt.plot(history_CNN_deleteoutliers['loss'], alpha=.3, color='#4D61E2', linestyle='--')\n",
        "# plt.plot(history_CNN_deleteoutliers['val_loss'], label='CNN_Clean', alpha=.8, color='#4D61E2')\n",
        "# plt.plot(history_CNN_Aug['loss'], alpha=.3, color='#4de2a1', linestyle='--')\n",
        "# plt.plot(history_CNN_Aug['val_loss'], label='CNN_Aug', alpha=.8, color='#4de2a1')\n",
        "# plt.title('Categorical Crossentropy')\n",
        "# plt.grid(alpha=.3)\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(loc='upper left')\n",
        "# plt.savefig('Categorical Crossentropy.jpg')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "suOuIw_7S0wM",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #plotting the validation and train ACC\n",
        "# plt.plot(history_CNN_simple['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
        "# plt.plot(history_CNN_simple['val_accuracy'], label='simple CNN', alpha=.8, color='#ff7f0e')\n",
        "# plt.plot(history_CNN_deleteoutliers['accuracy'], alpha=.3, color='#4D61E2', linestyle='--')\n",
        "# plt.plot(history_CNN_deleteoutliers['val_accuracy'], label='CNN_Clean', alpha=.8, color='#4D61E2')\n",
        "# plt.plot(history_CNN_Aug['accuracy'], alpha=.3, color='#4de2a1', linestyle='--')\n",
        "# plt.plot(history_CNN_Aug['val_accuracy'], label='CNN_Aug', alpha=.8, color='#4de2a1')\n",
        "# plt.title('model accuracy')\n",
        "# plt.grid(alpha=.3)\n",
        "# plt.legend(loc='upper left')\n",
        "# plt.savefig('Model Accuracy.jpg')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "9UD8PMZQS9-J",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MobileNET**"
      ],
      "metadata": {
        "id": "eQkeHG9c_2gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create MobileNetV2 model with specified settings\n",
        "input_shape = (96, 96, 3)\n",
        "mobile = tfk.applications.MobileNetV2(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    pooling='avg',\n",
        ")\n",
        "# tfk.utils.plot_model(mobile, show_shapes=True)"
      ],
      "metadata": {
        "id": "Eb1F31j2_2gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an input layer based on your input shape\n",
        "input_layer = tfkl.Input(shape=input_shape)\n",
        "\n",
        "# Connect MobileNetV2 to the input layer\n",
        "x = mobile(input_layer)\n",
        "\n",
        "x = tfkl.Dropout(0.5)(x)\n",
        "x = tfkl.Dense(512, activation=None, kernel_initializer = tf.keras.initializers.HeUniform(SEED))(x)\n",
        "x = tfkl.Dropout(0.5)(x)\n",
        "x = tfkl.Dense(128, activation='leaky_relu', kernel_initializer = tf.keras.initializers.HeUniform(SEED))(x)\n",
        "\n",
        "# Add a Dense layer with 2 units and softmax activation as the classifier\n",
        "outputs = tfkl.Dense(2, activation='softmax' , kernel_initializer=keras.initializers.HeUniform(SEED) )(x)\n",
        "\n",
        "# Create a Model connecting input and output\n",
        "MobileNetV2_model = tf.keras.Model(inputs=input_layer, outputs=outputs, name='model')\n",
        "\n",
        "# make it true for FT-\n",
        "MobileNetV2_model.get_layer('mobilenetv2_1.00_96').trainable = False\n",
        "\n",
        "# for i, layer in enumerate(MobileNetV2_model.get_layer('mobilenetv2_1.00_96').layers[:51]):\n",
        "#   layer.trainable=False\n",
        "\n",
        "# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\n",
        "MobileNetV2_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "MobileNetV2_model.summary()"
      ],
      "metadata": {
        "id": "763EX7p2_2gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function for callbacks for training\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 10, verbose=1,factor=0.2, min_lr=0.000001)\n",
        "# Model checkpoint\n",
        "mcp_save_model_mobile = ModelCheckpoint('MobileNetV2_model.hdf5', save_best_only=True, monitor='accuracy', mode='max')"
      ],
      "metadata": {
        "id": "SQZJRQ3C_2gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history_MobileNetV2_model = MobileNetV2_model.fit(\n",
        "    aug_train_set,\n",
        "    steps_per_epoch=len(aug_train_set),\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    callbacks=[learning_rate_reduction, mcp_save_model_mobile],\n",
        "    validation_data= validation_set,\n",
        "#     class_weight=class_weights\n",
        ")"
      ],
      "metadata": {
        "id": "8xLRzTkN_2gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the validation and train loss\n",
        "plt.plot(history_MobileNetV2_model.history['loss'])\n",
        "plt.plot(history_MobileNetV2_model.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yzXi5_OK_2gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the validation and train ACC\n",
        "plt.plot(history_MobileNetV2_model.history['accuracy'])\n",
        "plt.plot(history_MobileNetV2_model.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.savefig('Model Accuracy_MobileNet.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xAHlxvNC_2gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "true_labels = category_labels[validation_set.index_array]\n",
        "true_labels = true_labels.astype(int)\n",
        "\n",
        "prediction =MobileNetV2_model.predict(validation_set)\n",
        "binary_predictions = (prediction > 0.5).astype(int)\n",
        "\n",
        "cm = classification_report(true_labels, binary_predictions)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "BV5gzYpZ_2gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MobileNetV2_model.save('/kaggle/working/SubmissionModel')\n",
        "\n",
        "from shutil import make_archive\n",
        "make_archive('/kaggle/working/SubmissionModel_MobileNet', 'zip', '/kaggle/working/SubmissionModel')"
      ],
      "metadata": {
        "id": "YJI4JSnj_2gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet50**"
      ],
      "metadata": {
        "id": "VMXBtgpI_2gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet50_model(Hyparam):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "    GAP = layers.GlobalAveragePooling2D()\n",
        "    flatten_layer = tf.keras.layers.Flatten()\n",
        "    dropout = tf.keras.layers.Dropout(0.2)\n",
        "    dense_layer = layers.Dense(Hyparam, activation='relu', kernel_initializer = tf.keras.initializers.HeUniform(SEED))\n",
        "    dropout_1 = tf.keras.layers.Dropout(0.5)\n",
        "    prediction_layer = layers.Dense(2, activation='softmax')\n",
        "    batch_norm = layers.BatchNormalization()\n",
        "    Relu = layers.ReLU()\n",
        "    for layer in base_model.layers[:40]:\n",
        "        layer.trainable = False\n",
        "    model = Sequential([\n",
        "    base_model,\n",
        "    GAP,\n",
        "    dropout,\n",
        "    dense_layer,\n",
        "    batch_norm,\n",
        "    dropout_1,\n",
        "    prediction_layer\n",
        "    ])\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "QfqY2g2B_2gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet50=resnet50_model(128)\n",
        "model_resnet50.summary()"
      ],
      "metadata": {
        "id": "waYK8Q7G_2gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function for callbacks for training\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 3, verbose=1,factor=0.3, min_lr=0.000001)\n",
        "# Model checkpoint\n",
        "mcp_save_ResNet50 = ModelCheckpoint('model_ResNet50.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "metadata": {
        "id": "hbD2rJdR_2gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_ResNet50 = model_resnet50.fit(\n",
        "    aug_train_set,\n",
        "    steps_per_epoch=len(aug_train_set),\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    callbacks=[learning_rate_reduction, mcp_save_ResNet50],\n",
        "    validation_data= validation_set\n",
        "#     class_weight=class_weights\n",
        ")"
      ],
      "metadata": {
        "id": "GhpdT1Ye_2gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the validation and train loss\n",
        "plt.plot(history_ResNet50.history['loss'])\n",
        "plt.plot(history_ResNet50.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uOapZFBy_2gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the validation and train ACC\n",
        "plt.plot(history_ResNet50.history['accuracy'])\n",
        "plt.plot(history_ResNet50.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.savefig('Model Accuracy_ResNet.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zQyNSq-j_2gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "true_labels = category_labels[validation_set.index_array]\n",
        "true_labels = true_labels.astype(int)\n",
        "\n",
        "prediction =model_resnet50.predict(validation_set)\n",
        "binary_predictions = (prediction > 0.5).astype(int)\n",
        "\n",
        "cm = classification_report(true_labels, binary_predictions)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "lIGs9qa5_2gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet50.save('/kaggle/working/SubmissionModel')\n",
        "\n",
        "from shutil import make_archive\n",
        "make_archive('/kaggle/working/SubmissionModel_ResNet50', 'zip', '/kaggle/working/SubmissionModel')"
      ],
      "metadata": {
        "id": "fJZ07jXe_2gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EfficientnetB0**"
      ],
      "metadata": {
        "id": "zHsbo2c0_2gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def efficientnetB0_model(Hyparam,Hyparam_1):\n",
        "    # Load the pre-trained EfficientNetB0 model with weights from ImageNet\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "    GAP = layers.GlobalAveragePooling2D()\n",
        "    flatten_layer = tf.keras.layers.Flatten()\n",
        "    dropout = tf.keras.layers.Dropout(0.2,seed=SEED)\n",
        "    dense_layer = layers.Dense(Hyparam, activation=None, kernel_initializer = tf.keras.initializers.HeUniform(SEED))\n",
        "    dropout_1 = tf.keras.layers.Dropout(0.5,seed=SEED)\n",
        "    dense_layer_1 = layers.Dense(Hyparam_1, activation=None, kernel_initializer = tf.keras.initializers.HeUniform(SEED))\n",
        "    dropout_2 = tf.keras.layers.Dropout(0.1,seed=SEED)\n",
        "    prediction_layer = layers.Dense(2, activation='softmax')\n",
        "    batch_norm = layers.BatchNormalization()\n",
        "    batch_norm_1 = layers.BatchNormalization()\n",
        "    Relu = layers.ReLU()\n",
        "    for layer in base_model.layers[:90]:\n",
        "        layer.trainable = False\n",
        "    model = Sequential([\n",
        "    base_model,\n",
        "    GAP,\n",
        "    dropout,\n",
        "    dense_layer,\n",
        "    batch_norm,\n",
        "    dropout_1,\n",
        "    dense_layer_1,\n",
        "    batch_norm_1,\n",
        "    dropout_2,\n",
        "    prediction_layer\n",
        "    ])\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "epz5lPMa_2gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_efficientnetB0 = efficientnetB0_model(512,256)\n",
        "model_efficientnetB0.summary()"
      ],
      "metadata": {
        "id": "yBFLLJK1_2gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function for callbacks for training\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 5, verbose=1,factor=0.3, min_lr=0.000001)\n",
        "# Model checkpoint\n",
        "mcp_save_EfficientnetB0 = ModelCheckpoint('model_efficientnetB0.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "metadata": {
        "id": "UG365HA9_2gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_efficientnetB0 = model_efficientnetB0.fit(\n",
        "    aug_train_set,\n",
        "    steps_per_epoch=len(aug_train_set),\n",
        "    epochs=60,\n",
        "    verbose=1,\n",
        "    callbacks=[mcp_save_EfficientnetB0, mcp_save_ResNet50],\n",
        "    validation_data= validation_set,\n",
        ")"
      ],
      "metadata": {
        "id": "gN95qmKZ_2gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the validation and train loss\n",
        "plt.plot(history_efficientnetB0.history['loss'])\n",
        "plt.plot(history_efficientnetB0.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mVEWLMLx_2gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the validation and train ACC\n",
        "plt.plot(history_efficientnetB0.history['accuracy'])\n",
        "plt.plot(history_efficientnetB0.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.savefig('Model Accuracy_Efficientnet.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k-dw4P6Y_2gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "true_labels = category_labels[validation_set.index_array]\n",
        "true_labels = true_labels.astype(int)\n",
        "\n",
        "prediction =model_efficientnetB0.predict(validation_set)\n",
        "binary_predictions = (prediction > 0.5).astype(int)\n",
        "\n",
        "cm = classification_report(true_labels, binary_predictions)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "mGLdnIJ2_2gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_efficientnetB0.save('/kaggle/working/SubmissionModel')\n",
        "\n",
        "from shutil import make_archive\n",
        "make_archive('/kaggle/working/SubmissionModel_Efficien', 'zip', '/kaggle/working/SubmissionModel')"
      ],
      "metadata": {
        "id": "8Jkpm-bS_2gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**InceptionV3**"
      ],
      "metadata": {
        "id": "GtugMDxB_2gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create InceptionV3 model with specified settings\n",
        "input_shape = (96, 96, 3)\n",
        "mobile = tfk.applications.InceptionV3(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    pooling='avg',\n",
        ")\n",
        "# tfk.utils.plot_model(mobile, show_shapes=True)"
      ],
      "metadata": {
        "id": "4cpMZz1C_2gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an input layer based on your input shape\n",
        "input_layer = tfkl.Input(shape=input_shape)\n",
        "\n",
        "# Connect MobileNetV2 to the input layer\n",
        "x = mobile(input_layer)\n",
        "x = tfkl.Dropout(0.2)(x)\n",
        "x = tfkl.Dense(512, activation=None, kernel_initializer = tf.keras.initializers.HeUniform(SEED))(x)\n",
        "x = tfkl.BatchNormalization()(x)\n",
        "x = tfkl.Dropout(0.5)(x)\n",
        "x = tfkl.Dense(128, activation=None, kernel_initializer = tf.keras.initializers.HeUniform(SEED))(x)\n",
        "x = tfkl.Dropout(0.1)(x)\n",
        "x = tfkl.Dense(64, activation=None, kernel_initializer = tf.keras.initializers.HeUniform(SEED))(x)\n",
        "\n",
        "\n",
        "# Add a Dense layer with 2 units and softmax activation as the classifier\n",
        "outputs = tfkl.Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Create a Model connecting input and output\n",
        "InceptionV3_model = tf.keras.Model(inputs=input_layer, outputs=outputs, name='model')\n",
        "\n",
        "InceptionV3_model.get_layer('inception_v3').trainable = True\n",
        "for i, layer in enumerate(InceptionV3_model.get_layer('inception_v3').layers[:38]):\n",
        "  layer.trainable=False\n",
        "\n",
        "# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\n",
        "InceptionV3_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "InceptionV3_model.summary()"
      ],
      "metadata": {
        "id": "aZ9hnbuO_2gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function for callbacks for training\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 5, verbose=1,factor=0.3, min_lr=0.000001)\n",
        "# Model checkpoint\n",
        "mcp_save_InceptionV3 = ModelCheckpoint('InceptionV3_model.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "metadata": {
        "id": "FuhQAEzM_2gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history_InceptionV3_model = InceptionV3_model.fit(\n",
        "    aug_train_set,\n",
        "    epochs=60,\n",
        "    verbose=1,\n",
        "    callbacks=[learning_rate_reduction, mcp_save_InceptionV3],\n",
        "    validation_data= validation_set,\n",
        "    class_weight=class_weights\n",
        ")"
      ],
      "metadata": {
        "id": "I9Gko2UB_2gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the validation and train loss\n",
        "plt.plot(history_InceptionV3_model.history['loss'])\n",
        "plt.plot(history_InceptionV3_model.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pFaG0OBc_2gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the validation and train ACC\n",
        "plt.plot(history_InceptionV3_model.history['accuracy'])\n",
        "plt.plot(history_InceptionV3_model.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.savefig('Model Accuracy_InceptionV3.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GdapqRc5_2gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "true_labels = category_labels[validation_set.index_array]\n",
        "true_labels = true_labels.astype(int)\n",
        "\n",
        "prediction =InceptionV3_model.predict(validation_set)\n",
        "binary_predictions = (prediction > 0.5).astype(int)\n",
        "\n",
        "cm = classification_report(true_labels, binary_predictions)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "ruo5ZipK_2gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "InceptionV3_model.save('/kaggle/working/SubmissionModel')\n",
        "\n",
        "from shutil import make_archive\n",
        "make_archive('/kaggle/working/SubmissionModel_InceptionV3', 'zip', '/kaggle/working/SubmissionModel')"
      ],
      "metadata": {
        "id": "FFy1c-Q9_2gK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}